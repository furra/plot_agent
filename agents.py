from typing import TYPE_CHECKING

from baml_client.sync_client import b
from dotenv import load_dotenv
from langchain.agents import initialize_agent, AgentType
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
# from langfuse import observe
from langgraph.prebuilt import create_react_agent

from tools import PlotData, get_schema, python_repl_tool

load_dotenv()

if TYPE_CHECKING:
    from baml_client.types import SQLQuery
    from langchain.agents.agent import AgentExecutor
    from langgraph.graph.state import CompiledStateGraph
    from workflow import State


base_agent_prompt = (
    "You are a helpful AI assistant, collaborating with other assistants. "
    "Use the provided tools to progress towards answering the question. "
    "If you are unable to fully answer, that's OK, another assistant with different tools "
    "will help where you left off. Execute what you can to make progress."
)


class SQLAgent:
    """This agent converts the text query to a SQL query"""

    # @observe(name="sql-agent", as_type="generation")
    def invoke(self, query: str, engine: str = "sqlite") -> "SQLQuery":
        return b.GenerateSQLQuery(
            query,
            get_schema(),
            engine,
        )


sql_agent = SQLAgent()


class PlotAgent:
    # llm: "AgentExecutor"
    llm: "CompiledStateGraph"

    def __init__(self) -> None:
        # self.llm = initialize_agent(
        #     [python_repl_tool],
        #     init_chat_model("gemini-2.5-flash", model_provider="google_genai"),
        #     agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        #     verbose=True,
        # )
        self.llm = create_react_agent(
            init_chat_model("qwen/qwen3-32b", model_provider="groq"),
            [python_repl_tool],
            prompt=(
                f"{base_agent_prompt}\n"
                "You are a plotting agent that uses plotly and seaborn to generate plots."
                "You are working with a data extractor colleague. You will be given a pickle file and its location will be given. "
                "Generate one plot; if the user's full query is too complicated to answer in one plot, stick to one "
                "question/analysis, preferably the last sentence.\n"
                "Generate the plot first, then save the plot to a file in the same folder that the data file is. "
                "Provide the path in your output."
            )
        )

    # @observe(name="plot-agent", as_type="generation")
    def invoke(self, state: "State"):
        response = self.llm.invoke({
            # "input": state.get("messages")[-1].content  # for
            "messages": [state.get("user_query"), state.get("messages")[-1]]  # for react agents
        })
        return response


chart_agent = PlotAgent()

class PlotSummaryAgent:
    llm: "CompiledStateGraph"

    def __init__(self) -> None:
        self.llm = create_react_agent(
            init_chat_model("gemini-2.5-flash", model_provider="google_genai"),
            tools=[],  # Add image processing tools if available/needed.
            prompt=(
                f"{base_agent_prompt}\n"
                "You can only summarize the plot that was generated by the plot generator to answer the user's question. "
                "You are working with a researcher colleague and a plot generator colleague. "
                "Your task is to generate a standalone, concise summary for the provided plot image saved at a local `plot_path` "
                "which will be provided.\n"
                "The summary should be no more than 7 sentences and should not mention the plot itself. "
                "Add a conclusion at the end if it will help to answer the user's question."
            ),
        )

    # @observe(name="plot-summarizer-agent", as_type="generation")
    def invoke(self, state: "State"):
        return self.llm.invoke(state)


plot_summary_agent = PlotSummaryAgent()

